version: '3.8'

services:
  # Enhanced Flask Application
  app:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=development
      - DATABASE_URL=sqlite:///app/data/enhanced_users.db
      - REDIS_URL=redis://redis:6379/0
      - LITELLM_BASE_URL=http://litellm:4000
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./app/data:/app/data
      - ./config.env:/app/.env
    depends_on:
      - redis
      - litellm
      - ollama
    networks:
      - ai-network
    restart: unless-stopped

  # LiteLLM Proxy for Multiple AI Providers
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-1234567890abcdef}
      - LITELLM_SALT_KEY=${LITELLM_SALT_KEY:-sk-salt1234567890}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    networks:
      - ai-network
    restart: unless-stopped

  # Ollama for Local Models
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
    networks:
      - ai-network
    restart: unless-stopped
    # Uncomment if you have NVIDIA GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Open WebUI for Ollama Interface
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "8080:8080"
    volumes:
      - open-webui_data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=your-secret-key-here
    depends_on:
      - ollama
    networks:
      - ai-network
    restart: unless-stopped

  # Stable Diffusion WebUI for Image Generation
  stable-diffusion-webui:
    build:
      context: .
      dockerfile: Dockerfile.stable-diffusion
    ports:
      - "7860:7860"
    volumes:
      - stable_diffusion_models:/app/models
      - stable_diffusion_outputs:/app/outputs
    environment:
      - CLI_ARGS=--allow-code --medvram --xformers --enable-insecure-extension-access --api
    networks:
      - ai-network
    restart: unless-stopped
    # Uncomment if you have NVIDIA GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Whisper API for Speech-to-Text
  whisper-api:
    build:
      context: .
      dockerfile: Dockerfile.whisper
    ports:
      - "5001:5001"
    volumes:
      - whisper_models:/app/models
    networks:
      - ai-network
    restart: unless-stopped
    # Uncomment if you have NVIDIA GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Redis for Caching and Rate Limiting
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - ai-network
    restart: unless-stopped

  # Optional: Nginx for Load Balancing (Production)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    networks:
      - ai-network
    restart: unless-stopped
    profiles:
      - production

  # Optional: Database Backup Service
  db-backup:
    image: alpine:latest
    volumes:
      - ./app/data:/data
      - ./backups:/backups
    command: |
      sh -c "
      while true; do
        echo 'Creating database backup...'
        cp /data/enhanced_users.db /backups/backup_$$(date +%Y%m%d_%H%M%S).db
        find /backups -name 'backup_*.db' -mtime +7 -delete
        sleep 86400
      done
      "
    networks:
      - ai-network
    restart: unless-stopped
    profiles:
      - backup

volumes:
  ollama_data:
    driver: local
  redis_data:
    driver: local
  open-webui_data:
    driver: local
  stable_diffusion_models:
    driver: local
  stable_diffusion_outputs:
    driver: local
  whisper_models:
    driver: local

networks:
  ai-network:
    driver: bridge 